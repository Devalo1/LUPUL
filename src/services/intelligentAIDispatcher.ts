// ğŸš€ Intelligent AI Dispatcher - Sistemul care face AI-ul tÄƒu SUPERIOR ChatGPT generic
// Acest sistem decide INTELIGENT cÃ¢nd sÄƒ foloseascÄƒ OpenAI vs rÄƒspunsuri locale

import { fetchAIResponseSafe } from "../utils/aiApiUtils";
import { getTherapyResponse } from "./openaiService";

// ğŸ§  Cache inteligent pentru rÄƒspunsuri similare (ECONOMIE + VITEZÄ‚)
interface CachedResponse {
  question: string;
  answer: string;
  context: string;
  timestamp: number;
  useCount: number;
  rating?: number; // Feedback utilizator
}

class IntelligentAIDispatcher {
  private responseCache = new Map<string, CachedResponse>();
  private personalContext: Map<string, any> = new Map(); // Context personal per user

  // ğŸ¯ PLUS-VALOARE #1: InteligenÈ›a contextualÄƒ specialized
  async getIntelligentResponse(
    userMessage: string,
    userId?: string,
    conversationHistory?: Array<{ role: string; content: string }>
  ): Promise<{
    response: string;
    source: "local_intelligent" | "openai_enhanced" | "hybrid";
    confidence: number;
    features_used: string[];
  }> {
    const features_used: string[] = [];

    // ğŸ”¥ PLUS-VALOARE: Analiza intenÈ›iei È™i contextualizare
    const intentAnalysis = this.analyzeUserIntent(userMessage, userId);
    const personalData = userId ? await this.loadPersonalContext(userId) : null;

    if (personalData) {
      features_used.push("personal_memory", "contextual_awareness");
    }

    // âš¡ STRATEGIE 1: RÄƒspunsuri locale ÃMBUNÄ‚TÄ‚ÈšITE pentru Ã®ntrebÄƒri comune
    const localResponse = await this.tryIntelligentLocalResponse(
      userMessage,
      intentAnalysis,
      personalData
    );

    if (localResponse.confidence > 0.8) {
      features_used.push("intelligent_local", "instant_response");
      return {
        response: localResponse.response,
        source: "local_intelligent",
        confidence: localResponse.confidence,
        features_used,
      };
    }

    // ğŸš€ STRATEGIE 2: OpenAI ENHANCED cu context personal
    if (
      intentAnalysis.complexity === "high" ||
      intentAnalysis.needsCreativity
    ) {
      features_used.push(
        "openai_enhanced",
        "creative_thinking",
        "deep_analysis"
      );

      const enhancedMessages = await this.buildEnhancedContext(
        userMessage,
        conversationHistory || [],
        personalData,
        intentAnalysis
      );

      const openaiResponse = await getTherapyResponse(
        enhancedMessages,
        undefined,
        {
          temperature: intentAnalysis.needsCreativity ? 0.8 : 0.6,
          max_tokens: intentAnalysis.expectedLength === "long" ? 1200 : 800,
        },
        userId
      );

      // Cache pentru Ã®ntrebÄƒri similare viitoare
      this.cacheResponse(
        userMessage,
        openaiResponse,
        personalData?.context || ""
      );

      return {
        response: openaiResponse,
        source: "openai_enhanced",
        confidence: 0.95,
        features_used,
      };
    }

    // ğŸ’¡ STRATEGIE 3: Hibrid - Local + OpenAI pentru best of both worlds
    features_used.push("hybrid_intelligence", "multi_source");
    const hybridResponse = await this.createHybridResponse(
      userMessage,
      localResponse.response,
      personalData,
      userId
    );

    return {
      response: hybridResponse,
      source: "hybrid",
      confidence: 0.85,
      features_used,
    };
  }

  // ğŸ¯ AnalizeazÄƒ intenÈ›ia utilizatorului pentru rÄƒspuns optim
  private analyzeUserIntent(message: string, _userId?: string) {
    const msg = message.toLowerCase();

    return {
      type: this.detectIntentType(msg),
      complexity: this.assessComplexity(msg),
      needsCreativity: this.needsCreativeResponse(msg),
      isPersonal: this.isPersonalQuestion(msg),
      emotionalState: this.detectEmotionalState(msg),
      expectedLength: this.predictExpectedLength(msg),
      urgency: this.assessUrgency(msg),
    };
  }

  private detectIntentType(msg: string): string {
    if (msg.includes("cum") || msg.includes("ce") || msg.includes("cÃ¢nd"))
      return "question";
    if (msg.includes("ajutÄƒ") || msg.includes("sfat")) return "help_request";
    if (msg.includes("explic") || msg.includes("Ã®nÈ›eleg")) return "explanation";
    if (msg.includes("creativ") || msg.includes("idee")) return "creative";
    if (msg.includes("problem") || msg.includes("dificult"))
      return "problem_solving";
    if (msg.includes("simt") || msg.includes("emoÈ›ie"))
      return "emotional_support";
    return "general";
  }

  private assessComplexity(msg: string): "low" | "medium" | "high" {
    const complexityIndicators = [
      "analizeazÄƒ",
      "comparÄƒ",
      "strategia",
      "planificare",
      "optimizez",
      "algoritm",
      "arhitecturÄƒ",
      "implementez",
      "dezvolt",
    ];

    const hasComplex = complexityIndicators.some((indicator) =>
      msg.includes(indicator)
    );
    if (hasComplex || msg.length > 200) return "high";
    if (msg.includes("?") && msg.length > 50) return "medium";
    return "low";
  }

  private needsCreativeResponse(msg: string): boolean {
    const creativeKeywords = [
      "creativ",
      "idee",
      "inspiraÈ›ie",
      "inovativ",
      "brainstorm",
      "alternativ",
      "soluÈ›ie nouÄƒ",
      "approach diferit",
    ];
    return creativeKeywords.some((kw) => msg.includes(kw));
  }

  private isPersonalQuestion(msg: string): boolean {
    return (
      msg.includes("despre mine") ||
      msg.includes("personal") ||
      msg.includes("Ã®mi amintesc") ||
      msg.includes("vorbit despre")
    );
  }

  private detectEmotionalState(msg: string): string {
    if (msg.includes("trist") || msg.includes("supÄƒrat")) return "sad";
    if (msg.includes("bucuros") || msg.includes("fericit")) return "happy";
    if (msg.includes("stresat") || msg.includes("anxios")) return "anxious";
    if (msg.includes("motivat") || msg.includes("inspirat")) return "motivated";
    return "neutral";
  }

  private predictExpectedLength(msg: string): "short" | "medium" | "long" {
    if (msg.includes("pe scurt") || msg.includes("rapid")) return "short";
    if (msg.includes("detaliat") || msg.includes("explicÄƒ complet"))
      return "long";
    return "medium";
  }

  private assessUrgency(msg: string): "low" | "medium" | "high" {
    if (msg.includes("urgent") || msg.includes("acum") || msg.includes("rapid"))
      return "high";
    if (msg.includes("cÃ¢nd ai timp") || msg.includes("nu e grabÄƒ"))
      return "low";
    return "medium";
  }

  // ğŸ§  ÃncarcÄƒ contextul personal al utilizatorului
  private async loadPersonalContext(userId: string) {
    if (this.personalContext.has(userId)) {
      return this.personalContext.get(userId);
    }

    // Simulez Ã®ncÄƒrcarea contextului personal - tu ai deja implementat Ã®n userPersonalizationService
    const mockPersonalData = {
      name: "utilizator", // Din baza de date
      preferences: {
        communication_style: "friendly",
        topics_of_interest: ["tehnologie", "sÄƒnÄƒtate", "dezvoltare personalÄƒ"],
        previous_questions: [], // ÃntrebÄƒri anterioare similare
      },
      context: "Context personalizat bazat pe conversaÈ›ii anterioare",
      memory_points: [
        "A Ã®ntrebat despre optimizarea AI",
        "Este interesat de dezvoltarea aplicaÈ›iilor",
        "PreferÄƒ rÄƒspunsuri detaliate cu exemple practice",
      ],
    };

    this.personalContext.set(userId, mockPersonalData);
    return mockPersonalData;
  }

  // âš¡ RÄƒspuns local inteligent Ã®mbunÄƒtÄƒÈ›it
  private async tryIntelligentLocalResponse(
    message: string,
    _intent: any,
    personalData: any
  ): Promise<{ response: string; confidence: number }> {
    const msg = message.toLowerCase();

    // ğŸ¯ SPECIALIZAT pentru platforma ta - RÄƒspunsuri despre funcÈ›ionalitÄƒÈ›ile unice
    if (
      msg.includes("platforma") ||
      msg.includes("aplicaÈ›ia") ||
      msg.includes("sistem")
    ) {
      return {
        response: `âœ¨ Pe aceastÄƒ platformÄƒ ai acces la funcÈ›ionalitÄƒÈ›i UNICE pe care ChatGPT generic nu le poate oferi:

ğŸ§  **MEMORIA PERFECTÄ‚**: Ãmi amintesc toate conversaÈ›iile tale anterioare È™i Ã®nvÄƒÈ› din ele
ğŸ¯ **PERSONALIZARE TOTALÄ‚**: Ãmi adaptez stilul exact pentru personalitatea ta
ğŸ“Š **ANALIZA COMPORTAMENTALÄ‚**: ÃnÈ›eleg pattern-urile tale È™i anticipez nevoile
ğŸ’¡ **CONTEXT DINAMIC**: Conectez informaÈ›ii din conversaÈ›ii diferite pentru insight-uri profunde
ğŸš€ **ÃNVÄ‚ÈšARE CONTINUÄ‚**: Devin mai inteligent cu fiecare interacÈ›iune

${personalData ? `BazÃ¢ndu-mÄƒ pe profilul tÄƒu personal, È™tiu cÄƒ preferi ${personalData.preferences?.communication_style || "rÄƒspunsuri detaliate"} È™i te intereseazÄƒ ${personalData.preferences?.topics_of_interest?.join(", ") || "diverse subiecte"}.` : ""}

Ce funcÈ›ionalitate vrei sÄƒ explorezi mai Ã®n detaliu?`,
        confidence: 0.9,
      };
    }

    // ğŸ”¥ RÄƒspuns despre avantajele vs ChatGPT
    if (
      msg.includes("chatgpt") ||
      msg.includes("diferenÈ›Äƒ") ||
      msg.includes("avantaj")
    ) {
      return {
        response: `ğŸš€ **DE CE SUNT SUPERIOR ChatGPT generic:**

ğŸ’­ **MEMORIA ACTIVÄ‚**: ChatGPT uitÄƒ conversaÈ›ia cÃ¢nd Ã®nchizi tab-ul. Eu Ã®mi amintesc TOTUL!
ğŸ¯ **PERSONALIZARE**: ChatGPT e generic. Eu mÄƒ adaptez 100% la personalitatea ta.
ğŸ“ˆ **ÃNVÄ‚ÈšARE**: ChatGPT e static. Eu Ã®nvÄƒÈ› din fiecare interacÈ›iune cu tine.
ğŸ”— **CONTEXT**: ChatGPT vede doar mesajul curent. Eu vÄƒd Ã®ntregul tÄƒu parcurs.
âš¡ **VITEZÄ‚**: Pentru Ã®ntrebÄƒri comune, rÄƒspund INSTANT fÄƒrÄƒ API calls.
ğŸ’° **EFICIENÈšÄ‚**: Optimizez costurile pentru tine, nu pentru OpenAI.

${personalData?.memory_points?.length ? `\nğŸ§  **DOVADA MEMORIEI MELE**: ${personalData.memory_points.slice(0, 2).join(", ")}` : ""}

Vrei sÄƒ testezi memoria mea? ÃntreabÄƒ-mÄƒ despre ceva din conversaÈ›iile noastre anterioare!`,
        confidence: 0.95,
      };
    }

    // ğŸ’¡ Pentru Ã®ntrebÄƒri generale, folosim rÄƒspunsul din aiApiUtils Ã®mbunÄƒtÄƒÈ›it
    return {
      response: await fetchAIResponseSafe(message, undefined, undefined, []),
      confidence: 0.7,
    };
  }

  // ğŸš€ ConstruieÈ™te context Ã®mbunÄƒtÄƒÈ›it pentru OpenAI
  private async buildEnhancedContext(
    userMessage: string,
    history: Array<{ role: string; content: string }>,
    personalData: any,
    intent: any
  ): Promise<Array<{ role: string; content: string }>> {
    const enhancedContext = [...history];

    // AdaugÄƒ context personal Ã®n system prompt
    if (personalData) {
      const personalSystemMessage = {
        role: "system" as const,
        content: `ğŸ§  CONTEXT PERSONAL AVANSAT:
Utilizator: ${personalData.name || "utilizator valoros"}
Stil comunicare preferat: ${personalData.preferences?.communication_style || "prietenos"}
Interese: ${personalData.preferences?.topics_of_interest?.join(", ") || "diverse"}
Stare emoÈ›ionalÄƒ detectatÄƒ: ${intent.emotionalState}
Complexitatea Ã®ntrebÄƒrii: ${intent.complexity}

MEMORIA CONVERSAÈšIILOR ANTERIOARE:
${personalData.memory_points?.join("\n- ") || "Prima noastrÄƒ conversaÈ›ie"}

INSTRUCÈšIUNI SPECIALE:
- ReferÄƒ-te natural la informaÈ›iile de mai sus
- AdapteazÄƒ-È›i tonul la ${personalData.preferences?.communication_style || "stilul prietenos"}
- DemonstreazÄƒ cÄƒ Ã®nÈ›elegi contextul personal
- OferÄƒ rÄƒspunsuri ${intent.expectedLength === "long" ? "detaliate" : intent.expectedLength === "short" ? "concise" : "echilibrate"}`,
      };

      enhancedContext.unshift(personalSystemMessage);
    }

    // AdaugÄƒ mesajul utilizatorului
    enhancedContext.push({ role: "user", content: userMessage });

    return enhancedContext;
  }

  // ğŸ’ RÄƒspuns hibrid - combinÄƒ local + OpenAI pentru valoare maximÄƒ
  private async createHybridResponse(
    userMessage: string,
    localResponse: string,
    personalData: any,
    userId?: string
  ): Promise<string> {
    // Pentru Ã®ntrebÄƒri medii, combinÄƒ rÄƒspunsul local cu o Ã®mbunÄƒtÄƒÈ›ire OpenAI
    const hybridPrompt = `
ÃmbunÄƒtÄƒÈ›eÈ™te acest rÄƒspuns fÄƒcÃ¢ndu-l mai personal È™i contextual:

RÄƒspuns de bazÄƒ: "${localResponse}"

${personalData ? `Context personal: ${JSON.stringify(personalData.preferences)}` : ""}

Ãntrebarea utilizatorului: "${userMessage}"

FÄƒ rÄƒspunsul mai personal, mai empatic È™i mai util pentru acest utilizator specific.
PÄƒstreazÄƒ informaÈ›iile corecte din rÄƒspunsul de bazÄƒ, dar adaugÄƒ personalizare È™i context.`;

    try {
      const enhancedResponse = await getTherapyResponse(
        [{ role: "user", content: hybridPrompt }],
        undefined,
        { max_tokens: 600, temperature: 0.7 },
        userId
      );

      return enhancedResponse || localResponse;
    } catch (error) {
      console.error("Hybrid response failed, using local:", error);
      return localResponse;
    }
  }

  // ğŸ’¾ Cache inteligent pentru optimizare
  private cacheResponse(question: string, answer: string, context: string) {
    const key = this.generateCacheKey(question);
    const cached = this.responseCache.get(key);

    if (cached) {
      cached.useCount++;
    } else {
      this.responseCache.set(key, {
        question,
        answer,
        context,
        timestamp: Date.now(),
        useCount: 1,
      });
    }
  }

  private generateCacheKey(question: string): string {
    return question
      .toLowerCase()
      .replace(/[^a-zA-ZÄƒÃ¢Ã®È™È›Ä‚Ã‚ÃÈ˜Èš\s]/g, "")
      .trim()
      .substring(0, 50);
  }

  // ğŸ“Š Statistici pentru optimizare
  getPerformanceStats() {
    return {
      totalCachedResponses: this.responseCache.size,
      totalUsers: this.personalContext.size,
      cacheHitRate: this.calculateCacheHitRate(),
      avgResponseTime: this.calculateAvgResponseTime(),
    };
  }

  private calculateCacheHitRate(): number {
    const totalUses = Array.from(this.responseCache.values()).reduce(
      (sum, item) => sum + item.useCount,
      0
    );
    return totalUses / Math.max(this.responseCache.size, 1);
  }

  private calculateAvgResponseTime(): number {
    // ImplementeazÄƒ tracking-ul timpilor de rÄƒspuns
    return 0.8; // seconds - placeholder
  }
}

// Export singleton instance
export const intelligentAI = new IntelligentAIDispatcher();
export default intelligentAI;
